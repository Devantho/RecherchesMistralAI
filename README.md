# Les modÃ¨les
Les modÃ¨les les plus appropriÃ©s pour crÃ©e une ia capable de rÃ©pondre a des questions sur le logiciel Soins2000 semble Ãªtre:
- Ministral 8B
- Ministral 3B
- Open Mistral Nemo
Ne surtout pas utiliser magistral-medium, je n'ai obtenu que des mauvais rÃ©sultats.

La mÃ©thode appropriÃ© pour la comprÃ©hension de la documentation n'ai pas le fine tuning mais le RAG (Retrieval-Augmented Generation), rÃ©fÃ©rez vous a cette page: https://docs.mistral.ai/guides/rag/

Cependant, le fine-tuning peut Ãªtre utilisÃ© en plus du RAG pour affiner la forme et le format des rÃ©ponses. [Voir Fine-tuning](/Fine%20tuning.md)


# Les outils
Dans ce repos vous trouverez les outils suivant:
- Un outils en python permettant de [benchmark](/Programmes/ChatBot%20Python/benchmark.py) les modÃ¨le mistral et rendre un compte rendu au format MarkDown.
- Un [chatbot Python](/Programmes/ChatBot%20Python/) exploitant le principe du RAG. Il commence par convertir la documentation en vecteurs, quâ€™il stocke ensuite dans une base spÃ©cialisÃ©e (Faiss). Lorsquâ€™un utilisateur pose une question, celle-ci est Ã  son tour transformÃ©e en vecteurs pour rechercher les passages les plus pertinents dans la base. Le contenu trouvÃ© est alors fourni comme contexte au modÃ¨le afin de gÃ©nÃ©rer une rÃ©ponse adaptÃ©e.
- Un [client](/Programmes/Chatbot%20client-serveur%20C++/Client/) en c++ qui envoie les requÃªte des utilisateurs Ã  un serveur et reÃ§oit les rÃ©ponses.
- Un [serveur](/Programmes/Chatbot%20client-serveur%20C++/Serveur/) en c++ qui recoit les question, s'occupe du RAG puis de la gÃ©nÃ©ration du prompt pour finir par envoyer le prompt a l'[API Mistral](https://console.mistral.ai/) puis renvoyer la rÃ©ponse au client.
> Le client/serveur en c++ fournit de moins bonne rÃ©ponses que le ChatBot Python, cela viens de la mÃ©thode RAG qui est diffÃ©rente je pense.
- [Des benchmarks sur diffÃ©rent modÃ¨les](/benchmarks/)

# ğŸš€ Trois moyens dâ€™amÃ©liorer les performances dâ€™un modÃ¨le IA
![Illustration trois mÃ©thodes](https://www.dailydoseofds.com/content/images/size/w1200/2024/11/images_to_frame--5-.png)
## [Fine-tuning](Fine%20tuning.md)
RÃ©entraÃ®ner le modÃ¨le sur des donnÃ©es spÃ©cifiques pour quâ€™il adopte un ton, un style ou un savoir-faire particulier.

## RAG (Retrieval-Augmented Generation)
Connecter le modÃ¨le Ã  une base documentaire externe pour quâ€™il aille chercher des informations Ã  jour avant de rÃ©pondre.

## Prompting
Formuler des instructions prÃ©cises pour orienter la rÃ©ponse du modÃ¨le dans la bonne direction.
[Prompting Guide](https://docs.mistral.ai/guides/prompting_capabilities/)

## ğŸ§© Une combinaison puissante
UtilisÃ©s ensemble, ces trois leviers permettent dâ€™exploiter le plein potentiel dâ€™un modÃ¨le IA.
Le fine-tuning lui donne une personnalitÃ© ou une spÃ©cialisation mÃ©tier, le RAG garantit que ses rÃ©ponses sâ€™appuient sur des donnÃ©es fiables et rÃ©centes, et le prompting affine en temps rÃ©el la forme et le fond de la sortie.
Cette combinaison crÃ©e un assistant intelligent, pertinent et rÃ©actif, capable de sâ€™adapter Ã  la fois au contexte, Ã  lâ€™actualitÃ© et aux besoins de lâ€™utilisateur.

